\IEEEPARstart{G}{ame} playing has long been a active test bed for artificial intelligence research.
This has provided common goals and benchmarks across the research community, while capturing the imagination of the general public.
Many of the AI techniques developed for game playing have since been applied to further applications proving that this field of study is not just producing novel solutions.
\par
Examples of this include two major goals of AI research, the ability to play Chess and subsequently Go.
IBM's Deep Blue~\cite{deepBlue} created by Campbell et al. was the first chess engine to successfully beat the reining world champion in 1997.
After this the next milestone identified by the community was the game of Go, as it featured a vastly larger number of states making current AI methods ineffective. 
In 2016 this milestone was broken when Silver et al. created Deepmind's AlphaGo.
\par
Both Deep Blue and AlphaGo had a strong reliance on expert knowledge and used game specific features to help gain their success.
When Silver et al. refined alphaGo, creating alphaGoZero, they managed to achieve a similar level of performance without the crutch of prior human knowledge or game specific features beyond simple rules of the game~\cite{alphaGoZero}.
Furthermore by removing the crutch of domain specific knowledge, Silver et al. have managed to show that the alphaZero algorithm can achieve state-of-the-art performance on a variety of games (Go, Chess, and Shogi) without modification or utilising new human/game specific knowledge~\cite{alphaZero}.
\par
With AI game playing having great successes in board games, more complex games were sought out to use as a test-bed for AI methods.
Video games proved a logical step up for research as they had many benefits of traditional games, such as being well known and ease of measuring success, while providing new challenges with imperfect games, asymmetric games, stochastic outcomes, and vastly larger game states and decisions at each step.